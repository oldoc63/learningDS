
* Why Regularize?
Regularization plays a very important role in real world implementations of machine learning models. It is a statistical technique that /minimizes overfitting/ and is executed during the /model fitting step./ It is also an embedded feature selection method because it is implemented while the parameters of the model are being calculated.

Machine learning algorithms are rarely deployed to production without using some form of regularization. The reason for this is as follows: In practice, every model has to deal with the question o how well it can generalize from known to unknown data. We can train, test and tune models on known data and make them as accurate as possible. However, in deploying models, we are applying them on /new data./ Regularization makes sure that our model is still accurate.

In this lesson, we are going to learn how regularization minimizes overfitting and how ot use it as a feature selection method. Along the way, we are also going to learn two concepts that are very relevant to regularization and important just as standalone topics within machine learning, namely, the /bias-variance tradeoff/ and /hyperparameter tuning./ But first, we're going to answer the question: what is overfitting?

** Task 1
In the image to the right, we have three curves generated by different model fits to the same data. Can you identify which of these might be:

    underfitting the data?
    overfitting the data?

Fill in the number corresponding to the plots that best matches these on the code editor.

[[./overfitting_underfitting.png]]

* What is overfitting?
It might have been pretty apparent which of the three curves in the previous exercise overfit the set of points. However, often we have too many features to be able to visually assess if our model is overfitting our data or not. And so we need to qualify what we mean by overfitting exactly.

If a model is able to represent a particular set of data points effectively buy is not able to fit new data well, it is overfitting the data. Such a model has one or more of the followin attributes:

    - It fits the training data well but performs significantly worse on test data

    - It typically has more parameters than necessary, i.e., it has /high model complexity/

    - It might be fitting for features that are multi-collinear (i.e., features that are highly negatively or positively correlated)

    - It might be fitting the noise in the data and likely mistaking the noise for features

In practice, we often catch overfitting by comparing the model performance on the training data versus test data. For instance if the R-squared score is high for training data but the model performs pooly on test data, it's a strong indicator of overfitting. We're going to look at one such example now. A dataset has been loaded for you from the [[https://archive.ics.uci.edu/dataset/320/student+performance][UCI Machine Learning Repository]] that describes the performance in mathematics of students form two Portuguese schools. We're going to implement a multiple linear regression model to predict the final grade of the students based on a number of features in the dataset.

** Task 1
We've implemented some code to print the first five rows, set the target variable as y and the predictor variables as the matrix X. Calculate the number of features in the dataset, save it as num_features and press Run. (Note that the number of features is equal to the number of columns in X).

*Hint*
Set ~num_features~ equal to ~len(X.columns)~

** Task 2
We're about to fit the data to a model with 42 parameters! (Intercept plus 41 coefficients, one for each predictor variable). This might already make us apprehensive of the model potentially overfitting the data because:

    - the model likely has a high degree of complexity

    - we haven't checked for collinearity between the features

In order to assess whether we are overfitting, we're going to fit the model. In the workspace, you'll see that we've provided code to split the data into a training and test set, fit a regression on all 41 features, and calculated the mean squared error (MSE) on the training data.

In the section below the comment # 2.Testing Error, fill in the code to calculate the MSE for the test set. Save the result as ~MSE_test~ (currently set to None).

** Task 3
We see that the error on the test data is almost double the error with the training data! This is definitely an indicator of overfitting. We're now going to check the coefficients evaluated by the model to see if we can catch this.

Uncomment the plotting code below the comment #3:  Plotting the Coefficients and press Run to plot values of the coefficients produced.

We see that there are a few negatively correlated coefficients here (coefficients with roughly similar values mirrored about the axis), which is also a sign of overfitting.


** Script.py

#+begin_src python :results output
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt

  df = pd.read_csv("student_math.csv")
  print(df.head())

  # setting target and predictor variables
  y = df['Final_Grade']
  X = df.drop(columns = ['Final_Grade'])

  # 1. Number of features
  num_features = len(X.columns)
  print("Number of features: ", num_features)

  # Performing a Train-Test split
  from sklearn.model_selection import train_test_split
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

  # Fitting a Linear Regression Model
  from sklearn.linear_model import LinearRegression
  model = LinearRegression()
  model.fit(X_train, y_train)

  # Training Error
  pred_train = model.predict(X_train)
  MSE_train = np.mean((pred_train - y_train)**2)
  print("Training Error: ", MSE_train)

  # 2. Testing Error
  pred_test = model.predict(X_test)
  MSE_test = np.mean((pred_test - y_test)**2)
  print("Testing Error: ", MSE_test)

  # Calculating the regression coefficients
  predictors = X.columns
  coef = pd.Series(model.coef_,predictors).sort_values()

  # 3. Plotting the Coefficients
  plt.figure(figsize = (15,10))
  coef.plot(kind='bar', fontsize = 20)
  plt.title("Regression Coefficients", fontsize = 30)
  plt.show()

#+end_src

#+RESULTS:
#+begin_example
   age  Medu  Fedu  ...  higher_yes  internet_yes  romantic_yes
0   18     4     4  ...           1             0             0
1   17     1     1  ...           1             1             0
2   15     1     1  ...           1             1             0
3   15     4     2  ...           1             1             1
4   16     3     3  ...           1             0             0

[5 rows x 42 columns]
Number of features:  41
Training Error:  2.6268841802196254
Testing Error:  4.987346573982337
#+end_example
