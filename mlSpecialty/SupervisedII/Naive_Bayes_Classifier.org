
* Introduction to Bayes' Theorem
In this lesson, we'll learn about Bayes' Theorem. Bayes' Theorem is the basis of a branch of statistics called /Bayesian Statistics/, where we take prior knowledge into account before calculating new probabilities.

This allows us to find narrow solutions from a huge universe of possibilities. British mathematician Alan Turing used it to crack the German Enigma code during WWII. And now it is used in:

    - Machine Learning

    - Statistical Modeling

    - A/B Testing

    - Robotics

By the end of this lesson, you'll be able to solve simple problems involving prior knowledge.

Before we learn this theorem, we'll need to review independence and conditional probability.

[[./bayes_theorem.png]]

* Independent Events
The ability to determine whether two events are /independent/ is an important skill for statistics.

If two events are *independent*, then the occurrence of one event does not affect the probability of the other event. Here are some examples of independent events:

    - I wear a blue shirt; my coworker wears a blue shirt

    - I take the subway to work; I eat sushi for lunch

    - The NY Giants win their football game; the NY Rangers win their hockey game

If two events are *dependent* , then when one event occurs, the probability of the other event occurring changes in a predictable way.

Here are some examples of dependent events:

    - It rains on Tuesday; I carry an umbrella on Tuesday

    - I eat spaghetti; I have a red stain on my shirt

    - I wear sunglasses; I go to the beach

** Task 1
A certain family plans to have three children. Is the event that the couple's third child is a girl independent of the event that the couple's first two children are girls?

Save your answer('~independent~' or '~not independent~') to the variable ~third_child~.

* Conditional Probability
/Conditional Probability/ is the probability that two events happen. It's easiest to calculate  conditional probability when the two events are independent.

*Note*:
For the rest of this lesson, we'll be using the statistical convention that the probability of an event is written as ~P(event)~.

If the probability of event $A$ is $P(A)$ and the probability of event $B$ is $P(B)$ and the two events are independent, then the probability of both events occurring id the product of the probabilities:

$$
P(A \cap B) = P(A) \times P(B)
$$

The simbol \cap just means "and", so P(A \cap B) means the probability that both A and B happen.

For instance, suppose we are rolling a pair of dice, and want to know the probability of rolling two sixes.

[[./two_sixes.png]]

Each die has six sides, so the probability of rolling a six is 1/6. Each die is independent (i.e., rolling one six does not increase or decrease our chance of rolling a sencond six), so:

$$
P(6 \cap 6) = P(6) \times P(6) = \frac{1}{6} \times \frac{1}{6} = \frac{1}{36}
$$

** Task 1
This week, there is a 30% probability that it will rain on any given day. At a certain high school, gym class is held on three days out of the five day school week.

On a school day, what is the probability that it is raining and the strudents have gym class?

Save your answer to the variable ~p_rain_and_gym~.

#+begin_src python :results output
  import numpy as np

  p_rain_and_gym = .3 * (3/5)

  print(p_rain_and_gym)

#+end_src

#+RESULTS:
: 0.18

* Testing for a rare disease
Suppose you are a doctor and you need to test if a patient has a certain rare disease. The test is very accurate: it's correct 99% of the time. The disease is very rare: only 1 in 100,000 patients have it.

You administer the test and it comes back positive, so your patient must have the disease, right?

Not necessarily. If we just consider the test, there is only a 1% chance that it is wrong, but we actually have more information: we know how rare the disease is.

Given that the test came back positive, there are two possibilities:

    1. The patient had the disease, and the test correctly diagnosed the disease.

    2. The patient didn't have the disease and the test incorrectly diagnosed that they had the disease.

** Task 1
What is the probability that the patient had the disease *and* the test correctly diagnosed the disease?

Save your answer to the variable ~p_disease_and_correct~.

*Hint*
The disease is rare, so the probability that the patient had the disease is 1 out of 100,000:

$$
P(disease) = \frac{1}{100000}
$$

The test is only wrong 1% of the time, so it is correct 99% of the time:

$$
P(test \ is \ correct) = 0.99
$$

** Task 2
What is the probability that the patient /does not/ have the disease and the test incorrectly diagnosed the disease?

Save your answer to the variable ~p_no_disease_and_incorrect~.

*Hint*
The disease is rare, so the probability that the patient does not have the disease is 99,999 out of 100,000:

$$
P(disease) = \frac{99999}{100000}
$$

The test is only wrong 1% of the time:

$$
P(test\ is\ correct) = 0.01
$$

** Script.py

#+begin_src python :results output
  import numpy as np

  p_disease_and_correct = (1.0 / 100000) * 0.99

  print(p_disease_and_correct)

  p_no_disease_and_incorrect = (99999.0 / 100000) * 0.01

  print(p_no_disease_and_incorrect)

#+end_src

#+RESULTS:
: 9.9e-06
: 0.0099999

* Bayes' Theorem
In the previous exercise, we determine two probabilities:

    1. The patient had the disease, and the test correctly diagnosed the disease \approx 0.000001

    2. The patient didn't have the disease and the test incorrectly diagnosed that they had the disease \approx 0.01

Both events are rare, but we can see that it was about 1000 times more likely that the test was incorrect than that the patient had this rare disease.

We're able to come to this conclusion because we had more information than just the accuracy of the test; we alse knew the prevalence of this disease.

In statistics, if we have two events (A and B), we write the probability that event A will happen, given that event B already happened as $P(A \mid B)$. In our example, we want to find $P(rare\ disease \mid positive\ result)$. In other words, we want to find the probability that the patient has the disease /given/ the test came back positive.

We can calculate $P(A \mid B)$ using Bayes' Theorem, which states:

$$
P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}
$$

So in this case we'd say:

$$
P(rare\ disease \mid positive\ result) = \frac{P(positive\ result \mid rare\ disease) \cdot P(rare\ disease)}{P(positive\ result)}
$$

It is important to note that on the right side of the equation, we have the term $P(B \mid A)$. This is the probability that event B will happen given that event A has already happened. This is very different from $P(A \mid B)$, which is the probability we are trying to solve for. The order matters!

** Task 1
Calculate $P(positive\ result \mid rare\ disease)$, or the probability of a positive test result, given that a patient really has this rare disease.

Save your answer (as a decimal) to ~p_positive_given_disease~.

*Hint*
The test is 99% accurate, given the fact that the patient has the disease, we know that there is a 99% probability that the test will return a positive result.

This is exactly $P(positive\ result \mid rare\ disease)$.

** Task 2
What is $P(rare\ disease)$, the probability that a randomly selected patient has the rare disease?

Save your answer to ~p_disease~.

*Hint*
The disease is very rare. Only 1 in 100,000 people have it.

** Task 3
We now need to compute the denominator; we need to find $P(positive\ result)$:

    - The patient had the disease, *and* the test correctly diagnosed the disease.

    - The patient didn't have the disease *and* the test incorrectly diagnosed that they had the disease.

Using these two probabilities, calculate the total probability that a randomly selected patient receives a positive test result, $P(positive\ result)$.

Save your answer to the variable ~p_positive~.

*Hint*
The probability that the patient had the disease, *and* the test correctly diagnosed the disease is:

#+begin_src python
1.0 / 100000.0 * 0.99
#+end_src

The probability that the patient didn't have the disease *and* the test incorrectly diagnosed that they had the disease is:

#+begin_src python
99999.0 / 100000 * 0.01
#+end_src

The probability of either event A or event B happening is given by:

$$
P(A\ or\ B) = P(A) + P(B)
$$

** Task 4
Substitute all three of these values into Baye's Theorem and calculate $P(rare\ disease \mid positive\ result)$.

Save your result as ~p_disease_given_positive~.

** Script.py

#+begin_src python :results output
  import numpy as np

  p_positive_given_disease = 0.99

  p_disease = 1 / 100000

  p_positive = (1.0 / 100000.0 * 0.99) + (99999.0 / 100000 * 0.01)

  p_disease_given_positive = ((p_positive_given_disease * p_disease)) / p_positive

  print(p_disease_given_positive)

#+end_src

#+RESULTS:
: 0.0009890307498651321

* Spam Filters
Let's explore a different example. Email spam filters use Baye's Theorem to determine if certain words indicate that an email is spam.

Let's take a word that often appears in spam: "enhancement".

With just 3 facts, we can make some preliminary steps towards a good spam filter:

    1. "enhancement" appears  in just 0.1% of non-spam emails

    2. "enhancement" appears in 5% of spam emails

    3. Spam emails make up about 20% of total emails

Given that an email contains "enhancement" what is the probability that the email is spam?

** Task 1
In this example, we are dealing with two probabilities:

    - ~P(enhancement)~ -the probability that the word "enhancement" appears in an email.

    - ~P(spam)~ -the probability that an email is spam.

Using Bayes' Theorem to answer our question means that we want to calculate $P(A \mid B)$.

But what are A and B referring to in this case?

Save the string 'spam' to the variable ~a~.

Save the string 'enhancement' to the variable ~b~.

** Task 2
What is P(spam)?

Save your answer to ~p_spam~.

** Task 3
What is $P(enhancement \mid spam)$?

Save your answer to ~p_enhancement_given_spam~.

** Task 4
We want to know the overall probability that any email (spam or no spam) contains "enhancement".

Because we know the probability of "enhancement" ocurring in both spam (0.05) and non-spam (0.001) emails, we can use a /weighted average/ to calculate the probability of "enhancement" occurring in an email:

$$
P(enhancement) = P(enhancement \mid spam)×P(spam)+P(enhacement \mid not\  spam)×P(not\ spam)
$$

Save your answer to ~p_enhancement~.

** Task 5
Now that we know:

    - $P(spam)$

    - $P(enhancement \mid spam)$

    - $P(enhancement)$

We can plug this into Bayes' Theorem:

$$
P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}
$$

Save your answer as ~p_spam_enhancement~.

** Task 6
Print ~p_spam_enhancement~. This is the probability that an email is spam given that it contains the word "enhancement".

Should we block all emails that contain "enhancement"?

How much non-spam email would we block?

** Script.py

#+begin_src python :results output
  import numpy as np

  p_spam = 0.2

  p_enhancement_given_spam = 0.05

  p_enhancement = 0.05 * 0.2 + 0.001 * (1 - 0.2)

  p_spam_enhancement = (p_enhancement_given_spam *  p_spam) / p_enhancement

  print(p_spam_enhancement)

#+end_src

#+RESULTS:
: 0.9259259259259259

* Review
In this course, we learned several new definitions:

    - Two events are /independent/ if the occurrence of one event does not affect the probability of the second event

    - If two events are independent then:

      $$
      P(A \cap B) = P(A) \times P(B)
      $$

    - Bayes' Theorem is the following:

      $$
      P(A \mid B) = \frac{P(B \mid A) \cdot P(A) }{P(B)}
      $$

* The Naive Bayes Classifier
A Naive Bayes classifier is a supervised machine learning algorithm that leverages Bayes' Theorem to make predictions and classifications. Recall Bayes' Theorem:

$$
P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}
$$

This equation is finding the probability of A given B. This can be turned into a classifier if we replace B with a /data point/ and A with a /class./ For example, let's say we're trying to classify an email as either ~spam~ or ~not spam~. We could calculate $P(spam \mid email)$ and $P(not\ spam \mid email)$. /*Whichever probability is higher will be the classifier's prediction*./ Naive Bayes classifiers are often used for text classification.

So why is this a supervised machine learning algorithm? In order to compute the probabilities used in Bayes' Theorem, we need previous data points. For example, in the spam example, we'll need to compute $P(spam)$. This can be found by looking at a tagged dataset of emails and finding the ratio of spam to non-spam emails.

With the naive Bayes classifier, we are finding the probability that a data point d is a member of a class C using Bayes’ theorem: P(C|d) = P(C)*P(d|C) / P(d) . We can determine P(C) because this model is supervised and we have data. But what is P(d) ? How do we find the probability of a data point?

* Investigate the Data
In this lesson, we are going to create a Naive Bayes classifier that can predict whether a review for a product is positive or negative. This type of classifier could be extremely helpful for a company that is curious about the public reaction to a new product. Rather than reading thousands of reviews or tweets about the product, you could feed those documents into the Naive Bayes classifier and instantly find out how many are positive and how many are negative.

The dataset we will be using for this lesson contains Amazon product reviews for baby products. The original dataset contained many different features including the reviewer's name, the data the review was made, and the overall score. We've removed many of those features; the only features that we're interested in are the text of the review and whether the review was "positive" or "negative". We labeled all reviews with a score less than 4 as a negative review.

Note that in the next two lessons, we've only imported a small percentage of the data to help the code run faster. We'll import the full dataset later when we put everything together!

** Task 1
Let's look at the data given to us. Print ~pos_list[0]~. Would you classify this review as positive or negative?

** Task 2
Take a look at the first review in ~neg_list[0]~ as well. Does that one look negative?

** Task 3
We've also created a [[https://docs.python.org/3/library/collections.html#collections.Counter][Counter object]] for all the positive reviews and one for all of the negative reviews. These counters are like Python dictionaries -you could find the number of times the word "baby" was used in the positive reviews by printing ~pos_counter['baby']~.

Print the number of times the word "crib" was used in the positive and negative reviews. In which set was it used more often?

** Script.py

#+begin_src python
  from reviews import neg_list, pos_list, neg_counter, pos_counter

  print(pos_list[0])
  print(neg_list[0])

  print(pos_counter['crib'])
  print(neg_counter['crib'])

#+end_src

#+RESULTS:
: Traceback (most recent call last):
:   File "<stdin>", line 2, in <module>
: _pickle.UnpicklingError: invalid load key, '\xef'.
: [ Babel evaluation exited with code 1 ]

* Bayes Theorem I
For the rest of this lesson, we're going to write a classifier that can predict whether the review "This crib was amazing" is a positive or negative review. We want to compute both $P(positive \mid review)$ and $P(negative \mid review)$ and find which probability is larger. To do this, we'll be using Bayes' Theorem. Let's look at Bayes' Theorem for $P(positive \mid review)$.

$$
P(positive \mid review) = \frac{P(review \mid positive) \cdot P(positive)}{P(review)}
$$

The first part of Bayes' Theorem that we are going to tackle is $P(positive)$. This is the probability that any review is positive. To find this, we need to look at all of our reviews in our dataset -both positive and negative- and find the percentage of reviews that are positive.

We've bolded the part of Bayes' Theorem we're working on.

$$
P(positive \mid review) = \frac{P(review \mid positive) \cdot \textbf{P(positive)}}{P(review}
$$

** Task 1
Find the total number of positive reviews by finding the length of ~pos_list~. Do the same for ~neg_list~.

Add those two numbers together and save the sum in a variable called ~total_reviews~.

** Task 2
Create variables named ~percent_pos~ and ~percent_neg~. ~percent_pos~ should be the number of positive reviews divided by ~total_reviews~. Do the same for ~percent_neg~.

** Task 3
Print ~percent_pos~ and ~percent_neg~. They should add up to 1!

** Script.py

#+begin_src python
  from reviews import neg_list, pos_list, neg_counter, pos_counter

  number_positives_reviews = len(pos_list)
  number_negatives_reviews = len(neg_list)
  total_reviews = number_positives_reviews + number_negatives_reviews

  percent_pos = number_positives_reviews / total_reviews

  percent_neg = number_negatives_reviews / total_reviews

  print(percent_pos)
  print(percent_neg)
#+end_src
