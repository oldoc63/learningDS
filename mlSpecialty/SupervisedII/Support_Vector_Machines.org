
* Supervised Learning Part II
You've already built a foundation in supervised machine learning, now it's time to go deeper and learn about another set of algorithms that built on the algorithms you've already learned about!

** What will Supervised Learning for Data Science (Part II) Cover?
After this unit, you will be able to use and apply:

    - Support Vector Machines (SVMs)

    - Recommender Systems

    - Naive Bayes Classification

** Support Vector Machines
A *Support Vector Machine* (SVM) is a powerful supervised machine learning model used for classification. An SVM makes classifications by defining a decision boundary and then seeing what side of the boundary an unclassified point falls on. In the next few exercises, we'll learn how these decision boundaries get defined, but for now, know that they're defined by using a training set of classified points. That's why SVMs are /supervised/ machine learning models.

Decision boundaries are easiest to wrap your head around when the data has two features. In this case, the decision boundary is a line. Take a look at the example below.

[[./decision_boundary.png]]

This SVM is using data about fictional games of Quidditch from the Harry Potter universe! The classifier is trying to predict whether a team will make the playoffs or not. Every point in the training set represents a "historical" Quidditch team. Each point has two features -the average number of goals the team scores and the average number of minutes it takes the team to catch the Golden Snitch.

After finding a decision boundary using the training set, you could give the SVM an unlabeled data point, ant it will predict whether or not that team will make tha playoffs.

Decision boundaries exist even when your data has more than two features. If there are three features, the decision boundary is now a plane rather than a line.

[[./three_features_svm.png]]

As the number of dimensions grows past 3, it becomes very difficult to visualize these points in space. Nonetheless, SVMs can still find a decision boundary. However, rather than being a separating line, or separating plane, the decision boundary is called a /separating hyperplane./

*** Task 1
Run the code to see two graphs appears. Right now they should be identical. We're going to fix the bottom graph so it has a good decision boundary. Why is this decision boundary bad?

*** Task 2
Let's shift the line on the bottom graph to make it separate the two clusters. The slope of the line looks pretty good, so let's keep that at -2.

We want to move the boundary up, so change ~intercept_two~ so the line separates the two clusters.

*** Script.py

#+begin_src python
  import codecademylib3_seaborn
  import matplotlib.pyplot as plt
  import numpy as np
  from graph import ax, x_1, y_1, x_2, y_2

  #Top graph intercept and slope
  intercept_one = 8
  slope_one = -2

  x_vals = np.array(ax.get_xlim())
  y_vals = intercept_one + slope_one * x_vals
  plt.plot(x_vals, y_vals, '-')

  #Bottom Graph
  ax = plt.subplot(2, 1, 2)
  plt.title('Good Decision Boundary')
  ax.set_xlim(0, 10)
  ax.set_ylim(0, 16)

  plt.scatter(x_1, y_1, color = "b")
  plt.scatter(x_2, y_2, color = "r")

  #Change the intercept to separate the clusters
  intercept_two = 15
  slope_two = -2

  x_vals = np.array(ax.get_xlim())
  y_vals = intercept_two + slope_two * x_vals
  plt.plot(x_vals, y_vals, '-')

  plt.tight_layout()
  plt.show()

#+end_src

#+RESULTS:

[[./good_bad_decision_boundary.png]]

** Optimal Decision Boundaries
One problem that SVMs need to solve is figuring out what decision boundary to use. After all, there could be an *infinite* number of decision boundaries that correctly separate the two classes. Take a look at the image below:

[[./optimal_boundary.png]]

There are so many valid decision boundaries, buy which one is best? In general, we want our decision boundary to be /as far away/ from training points as possible.

Maximizing the distance between the decision boundary and points in each class will decrease the chance of false classification. Take graph C for example:

[[./close_blue_class.png]]

The decision boundary is close to the blue class, so it is possible that a new point close to the blue cluster would fall on the red side of the line.

Out of all the graphs shown here, graph F has the best decision boundary.

*** Task 1
Run the code. Both graphs have suboptimal diecidion boundaries. Why? Because these boundaries are too close to the training data. We're goin to fix the bottom graph.

*** Task 2
We're going to have to make the decision boundary much flatter, which means we first need to lower its y-intercept. Change ~intercept_two~ to be 8.

*** Task 3
Next, we want the slope to be pretty flat. Change the value of ~slope_two~. The resulting line should split the two clusters.

*Hint*
~slope_two = -0.5~ works well!


*** Script.py

  #+begin_src python
  import codecademylib3_seaborn
  import matplotlib.pyplot as plt
  import numpy as np
  from graph import ax, x_1, y_1, x_2, y_2

  #Top graph intercept and slope
  intercept_one = 98
  slope_one = -20

  x_vals = np.array(ax.get_xlim())
  y_vals = intercept_one + slope_one * x_vals
  plt.plot(x_vals, y_vals, '-')

  #Bottom graph
  ax = plt.subplot(2, 1, 2)
  plt.title('Good Decision Boundary')
  ax.set_xlim(0, 10)
  ax.set_ylim(0, 10)

  plt.scatter(x_1, y_1, color = "b")
  plt.scatter(x_2, y_2, color = "r")

  #Bottom graph intercept and slope
  intercept_two = 98
  slope_two = -20

  x_vals = np.array(ax.get_xlim())
  y_vals = intercept_two + slope_two * x_vals
  plt.plot(x_vals, y_vals, '-')

  plt.tight_layout()
  plt.show()

#+end_src

[[./optimal_intercept_slope.png]]

** Support Vectors and Margins
We now know that we want our decision boundary to be as far away form our training points as possible. Let's introduce some new terms that can help explain this idea.

The /support vectors/ are the points in the training set closest to the decision boundary. In fact, these vectors are what define the decision boundary. In fact, these vectors are what define the decision boundary. But why are they called vectors? Instead of thinking about the training data as points, we can think of then as vectors coming from the origin.

[[./vectors_define_decision_boundary.png]]

These vectors are crucial in defining the decision boundary -that's where the "support" comes from. If you are using ~n~ features, there are at least ~n+1~ support vectors.

The distance between a support vector and the decision boundary is called the /margin/. We want to make the margin as large as possible. The support vectors are highlighted in the image below:

[[./support_vector_margin.png]]

Because the support vectors are so critical in defining the decision boundary, many of the other training points can be ignored. This is one of the advantages od SVMs. Many supervised machine learning algorithms use every training point in order to make a prediction, even though many of those training points aren't relevant. SVMs are fast because they only use the support vectors!

*** Task 1
What are the support vectors for the SVM pictured below? There should be 2 blue support vectors and 1 red support vector.

*** Task 2
What is the size of the marging?

** Support Vector Machines: scikit-learn
Now that we know the concepts behind SVMs we need to write the code that will find the decision boundary that maximizes the margin. All of the code that we've written so far has been guessing and checking -we don't actually know if we've found the best line. Unfortunately, calculating the parameters of the best decision boundary is a fairly complex optimization problem. Luckily, Python's scikit-learn library has implemented an SVM that will do this for us.

Note that while it is not important to understand how the optimal parameters are found, you should have a strong conceptual understanding of what the model is optimizing.

To use scikit-learn's SVM we first need to create an SVC object. It is called an SVC because scikit-learn is calling the model a Support Vector Classifier rather than a Support Vector Machine.

#+begin_src python
  classifier = SVC(kernel='linear')
#+end_src

We'll soon go into what the ~kernel~ parameter is doing, but for now, let's use a 'linear' kernel.

Next, the model needs to be trained on a list of data points and a list of labels associated with those data points. The labels are analogous to color of the point -you can think of a ~1~ as a red point and a ~0~ as a blue point. The training is done using the ~.fit()~ method:

#+begin_src python
  training_points = [[1, 2], [1, 5], [2, 2], [7, 5], [9, 4], [8, 2]]
  labels = [1, 1, 1, 0, 0, 0]
  classifier.fit(training_points, labels)
#+end_src

The graph of this dataset would look like this:

[[./graph_dataset.png]]

Calling ~.fit()~ creates the line between the points.

Finally, the classifier predicts the label of new points using the ~.predict()~ method. The ~.predict()~ method takes a list of points you want to classify. Even if you only want to classify one point, make sure it is in a list:

#+begin_src python
  print(classifier.predict([3, 2]))
#+end_src

In the image below, you can see the unclassified point ~[3, 2]~ as a black dot. It falls on the red side of the line, so the SVM would predict it is red.

In addition to using the SVM to make predictions, you can inspect some of its attributes. For example, if you can print ~classifier.support_vectors_~ to see which points from the training set are the support vectors.

In this case, the support vectors look like this:

#+begin_example
[[7, 5],
 [8, 2],
 [2, 2]]
#+end_example

*** Task 1
Let's start by making a ~SVC~ object with ~kernel='linear'~. Name the object ~classifier~.

*** Task 2
We've imported the training set and labels for you. Call ~classifier~'s ~.fit()~ method using ~points~ and ~labels~ as parameters.

*** Task 3
We can now classify new points. Try classifying both ~[3, 4]~ and ~[6, 7]~. Remember, the ~.predict()~ function expects a list of points to predict.

*** Script.py

#+begin_src python
  from sklearn.svm import SVC
  from graphs import points, labels

  classifier = SVC(kernel='linear')
  classifier.fit(points, labels)
  print(classifier.predict([[3, 4], [6, 7]]))
#+end_src

#+RESULTS:

** Outliers
SVMs try to maximize the size of the marging while still correctly separating the points of each class. As a result, outliers can be a problem. Consider de image below.

[[./outliers_svm.png]]

The size of the margin decreases when a single outlier is present, and as a result, the decision boundary changes as well. However, if we allowed the decision boundary to have some error, we could still use the original line.

SVMs have a parameter ~C~ that determines how much error the SVM will allow for. If ~C~ is large, then the SVM has a hard margin -it won't allow for many missclassifications, and as a result, the margin could be fairly small. If ~C~ is too large, the model runs the risk of overfitting. It relies too heavily on the training data, including the outliers.

On the other hand, if ~C~ is small, the SVM has a soft margin. Some points might fall on the wrong side of the line, buy the margin will be large. This is resistant to outliers, but if ~C~ gets too small, you run the risk of underfitting. The SVM will allow for so much error that the training data won't be represented.

When using scikit-learn's SVM, you can set the value of ~C~ when you create the object:

#+begin_src python
  classifier = SVC(C=0.01)
#+end_src

The optimal value of ~C~ will depend on your data. Don't always maximize margin size at the expense of error. Don't always minimize error at the expense of margin size. The best strategy is to validate your model by testing many different values for ~C~.

*** Task 1
Run the code to see the SVM's current boundary line. Note that we've imported some helper functions we wrote named ~draw_points~ and ~draw_margins~ to help visualize the SVM.

*** Task 2
Let's add an outlier! Before calling ~.fit()~, ~append 0~ to ~labels~. This will add a blue point at ~[3, 3]~.

*** Task 3
Right now, our classifier has hard margins because ~C = 1~. Change the value of ~C~ to ~0.01~ to see what the SVM looks like with soft margins.

*** Task 4
~append~ at least two more points to points. If you want the ~points~ to appear on the graph, make sure their x and y values are between ~0~ and ~12~.

Make sure to also ~append~ a label to labels for every point you add. A 0 will make the point blue and a 1 will make the point red.

Make sure to add the points before training the SVM.

*** Task 5
Play around with the ~C~ variable to see how the decision boundary changes with your new points added. Change ~C~ to be a value between ~0.01~ and ~1~.


*** Script.py

#+begin_src python
  import codecademylib3_seaborn
  import matplotlib.pyplot as plt
  from sklearn.svm import SVC
  from graph import points, labels, draw_points, draw_margin

  classifier = SVC(kernel='linear', C=1)
  classifier.fit(points, labels)

  draw_points(points, labels)
  draw_margin(classifier)

  plt.show()
#+end_src

[[./outliers_graph_hard_margins.png]]

[[./outliers_graph_soft_margins.png]]

** Kernels
Up to this point, we have been using data sets that are linearly separable. This means that it's possible to draw a straight decision boundary between the two classes. However, what would happen if an SVM came along a data set that wasn't linearly separable?

[[./non_linearly_separable.png]]

It's impossible to draw a straight line to separate the red points from the blue points!

Luckily, SVMs have a way of handling these data sets. Remember when we set ~kernel='linear'~ when creating our SVM? Kernels are the key to creating a decision boundary between data points that are not linearly separable.

Note that most machhine learning models should allow for some error. For example, the image below shows data that isn't linearly separable. However, it is not linearly separable due to a few outliers. We can still draw a straight line that, for the most part, separates the two classes. You shouldn't need to create a non-linear decision boundary just to fit some outliers. Drawing a line that correctly separates every point would be drastically overfitting the model to the data.

[[./non_linearly_separable_data_due_to_outliers.png]]

*** Task 1
Let's take a look at the power of kernels. We've created a dataset that isn't linearly separable and split it into a training set and a validation set.

Create an ~SVC~ named ~classifier~ with a ~'linear'~ kernel.

*** Task 2
Call the ~.fit()~ method using ~training_data~ and ~training_labels~ as parameters.

*** Task 3
Let's see how accurate our classifier is using a linear kernel.

Call ~classifier~'s ~.score()~ function using ~validation_data~ and ~validation_labels~ as parameters. Print the results.

This will print the average accuracy of the model.

*** Task 4
That's pretty bad! The classifier is getting it right less than 50% of the time! Change ~'linear'~ to ~'poly'~ and add the parameter ~degree=2~. Run the program again and see what happens to the score.

*** Script.py

#+begin_src python
  import codecademylib3_seaborn
  from sklearn.svm import SVC
  from graph import points, labels
  from sklearn.model_selection import train_test_split

  training_data, validation_data, training_labels, validation_labels = train_test_split(points, labels, train_size=0.8, test_size=0.2, random_state=100)

  classifier = SVC(kernel='poly', degree=2)
  classifier.fit(training_data, training_labels)
  (classifier.score(validation_data, validation_labels))

#+end_src

** Polynomial Kernel
That kernel seems pretty magical. It is able to correctly classify every point! Let's take a deeper look at what it was really doing.

We start with a group of non-linearly separable points that looked like this:

[[./non_linearly_separable.png]]

The kernel transforms the data in a clever way to make it linearly separable. We used a polynomial kernel which transform every point in the following way:

$$
(x, y) \rightarrow (\sqrt{2} \  \cdot \  x \ \cdot \ y, \  x^2, \ y^2)
$$

The kernel has added a new dimension to each point! For example, the kernel transforms the point ~[1, 2]~ like this:

$$
(1, 2) \rightarrow (2 \sqrt{2}, 1, 4)
$$

If we plot these new three dimensional points, we get the following graph:

[[./twod_data_projected_into_threed.png]]

Look at that! All of the blue points have scooted away from the red ones. By projecting the data into a higher dimension, the two classes are now linearly separable by a plane.

*** Task 1
In this exercise, we will be using a non-linearly separable dataset similar to the concentric circles above.

Rather than using a polynomial kernel, we're going to stick with a linear kernel and do the transformation ourselves. The SVM running a linear kernel on the transformed points should perform identically to the SVM running a polynomial kernel on the original points.

To begin, at the bottom of your code, print  ~training_data[0]~ to see the first data point. You will also see the accuracy of the SVM when the data is not projected into 3 dimensions.

*Hint*
The SVM is pretty bad! Because it is using a linear kernel, it is trying to draw a straight decision boundary.

*** Task 2
Let's transform the data into three dimensions! Begin by creating two empty lists called ~new_training~ and ~new_validation~.

*** Task 3
Loop through every point in ~training_data~ and ~validation_data~. For every ~point~, ~append~ a list to ~new_training~. The list should contain three numbers:

    - The square root of ~2~ times ~point[0]~ times ~point[1]~

    - ~point[0]~ squared

    - ~point[1]~ squared

Remember, to square a number in Python do ~number ** 2~. To take the square root, do ~number ** 0.5~.

*** Task 4
Retrain ~classifier~ by calling the ~.fit()~ method using ~new_training~ and ~training_labels~ as parameters.

*** Task 5
Finally, run ~classifier~'s ~.score()~ method using ~new_validation~ and ~validation_labels~ as parameters. Print the results. How did the SVM do when the data was projected to three dimensions?

*Hint*
The classifier should be 100% accurate! Pretty cool! We didn't change anything about the classifier, *we just changed the data*.

*** Script.py

#+begin_src python :results output
  from sklearn.datasets import make_circles
  from sklearn.svm import SVC
  from sklearn.model_selection import train_test_split

  # Makes concentric circles
  points, labels = make_circles(n_samples=300, factor=.2, noise=.05, random_state=1)

  # Makes training set and validation set
  training_data, validation_data, training_labels, validation_labels = train_test_split(points, labels, train_size=0.8, test_size=0.2, random_state=100)

  classifier = SVC(kernel="linear", random_state=1)
  classifier.fit(training_data, training_labels)
  print(classifier.score(validation_data, validation_labels))

  print(training_data[0])

  new_training = [[2 ** 0.5 * pt[0] * pt[1], pt[0]**2, pt[1]**2] for pt in training_data]
  new_validation = [[2 ** 0.5 * pt[0] * pt[1], pt[0]**2, pt[1]**2] for pt in validation_data]

  classifier.fit(new_training, training_labels)
  print(classifier.score(new_validation, validation_labels))

#+end_src

#+RESULTS:
: 0.5666666666666667
: [0.31860062 0.11705731]
: 1.0

** Radial Basis Function Kernel
The most commonly used kernel in SVMs is a radial basis function (*rbf*) kernel. This is the default kernel used in scikit-learn's ~SVC~ object. If you don't specifically set the kernel to ~"linear"~, ~"poly"~ the ~SVC~ object will use an rbf kernel. If you want to be explicit, you can set ~kernel = "rbf"~, although that is redundant.

It is very tricky to visualize how an rbf kernel "transforms" the data. The polynomial kernel we used transformed two-dimensional points into three-dimensional points. An rbf kernel transforms two-dimensional points into points with an infinite number of dimensions!

We won't get into how the kernel does this -it involves some fairly complicated linear algebra. However, it is important to know about the rbf kernel's ~gamma~ parameter.

#+begin_src python
classifier = SVC(kernel="rbf", gamma=0.5, C=2)
#+end_src

~gamma~ is similar to the ~C~ parameter. You can essentially tune the model to be more or less sensitive to the training data. A higher ~gamma~, say ~100~, will put more importance on the training data and could result in overfitting. Conversely, a lower ~gamma~ like ~0.01~ makes the points in the training data less relevant and can result in underfitting.

*** Task 1
We're going to be using a rbf kernel to draw a decision boundary for the following points:

[[./rbf_non_linear_dataset.png]]

We've imported the data and split it into ~training_data~, ~validation_data~, ~training_labels~, and ~validation_labels~.

Begin by creating an ~SVC~ named ~classifier~ with an ~"rbf"~ kernel. Set the kernel's ~gamma~ equal to ~1~.

*** Task 2
Next, train the model using the ~.fit()~ method using ~training_data~ and ~training_labels~ as parameters.

*** Task 3
Let's test the classifier's accuracy when its ~gamma~ is ~1~. Print the result of the ~.score()~ function using ~validation_data~ and ~validation_labels~ as parameters.

*Hint*
The decision boundary when ~gamma = 1~ looks like this:

[[./decision_boundary_gamma_1.png]]

*** Task 4
Let's see what happens if we increase ~gamma~. Change ~gamma~ to ~10~. What happens to the accuracy of our model?

*Hint*
The decision boundary when ~gamma = 10~ looks like this:

[[./decision_boundary_gamma_10.png]]

*** Task 5
The accuracy went down. We overfit our model. Change ~gamma~ to ~0.1~. What happens to the accuracy of our model this time?

*Hint*
Now we're underfitting. The decision boundary looks like this:

[[./decision_boundary_gamma_01.png]]

*** Script.py

#+begin_src python
  from data import points, labels
  from sklearn.model_selection import train_test_split
  from sklearn.smv import SVC

  training_data, validation_data, training_labels, validation_labels = train_test_split(points, labels, train_size=0.08, test_size=0.2, random_state=100)

  classifier = SVC(kernel="rbf", gamma=1)
  classifier.fit(training_data, training_labels)
  print(classifier.score(validation_data, validation_labels))

#+end_src

#+RESULTS:

** Review
Here are some of the major takeaways from this lesson on SVMs:

    - SVM are supervised machine learning models uses for classification.

    - An SVM uses support vectors to define a decision boundary. Classifications are made by comparing unlabeled points to that decision boundary.

    - Support vectors are the points of each class closest to the decision boundary. The distance between the support vectors and the decision boundary is called the margin.

    - SVMs attempt to create the largest margin possible while staying within an acceptable amount of error.

    - The ~C~ parameter controls how much error is allowed. A large ~C~ allows for little error and creates a hard margin. A small ~C~ allows for more error and creates a soft margin.

    - SVMs use kernels to classify points that aren't linearly separable.

    - Kernels transform points into higher dimensional space. A polynomial kernel transforms points into three dimensions while an rbf kernel transforms points into infinite dimensions.

    - An rbf kernel has a ~gamma~ parameter. If ~gamma~ is large, the training data is more relevant, and as a result overfitting can occur.

** Quiz

*** Question 1
Which of the following SVMs with an rbf kernel has the largest ~gamma~ parameter?

    - *C*

      Correct! The highest ~gamma~ will be the graph that is most overfit to the data. The decision boundary will be very specific to the training set.

*** Question 2
What are the support vectors in an SVM?

    - The points in the training set closest to the decision boundary.

      Correct! These points help define the decision boundary.

*** Question 3
Why is it important for an SVM to maximize the size of its marging?

    - A large margin prevents points in the training set form being close to the decision boundary.

      Correct! We want these points as far away from the boundary as possible. There is less room for error if they are right next to the boundary.

*** Question 4
An SVM has a soft margin when:

    - The marging is large and the decision boundary allows for many errors

      Correct! A soft margin could result in underfitting.

*** Question 5
What happens to a Support Vector Machine if ~C~ is to large?

    - Overfitting will occur due to the marging becoming too small

      Correct! If C is large, the SVM will try to make the decision boundary work for every point, even if it is an outlier.

*** Question 6
What are the inputs of the ~.fit()~ method in scikit-learn's ~SVC~ class?

    - A list of training points and a list of labels associated with those points.

      Correct! These both have to be lists, even if you're only training with one data point (which you probably shouldn't do!)

*** Question 7
If your data is in three dimensions, the decision boundary will be a:

    - Plane

      Correct! A plane can separate points in three dimensions.

*** Question 8
Which of the following SVMs has an optimal decision boundary?

    - *A*
      Correct! That decision boundary is far away from both clusters.

*** Question 9
What is the role of a kernel in an SVM?

    - A kernel transforms the data into a higher dimension so it can be linearly separable.

      Correct! Kernels help make decision boundaries for points that are not linearly separable.
