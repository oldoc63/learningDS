
* An Introduction to Unsupervised Learning
Unsupervised Learning describes a class of algorithms that find patterns from /unlabelled or untagged/ data. In supervised learning, we deal with data that is labelled or tagged. For example, we predict continuous outcomes in /regression/ (for instance, predictin housing prices) or categorical outcomes in /classification/ (spam versus not spam, for example). However, often training data isn't labelled in this manner and this is where unsupervised learning comes in! It relies on using the *underlying distributions of features within the data* to figure out clusters of similarity.

Unsupervised learning methods are extremely important to the functioning of many real-world algorithms -think image recognition, ride-shares anticipating demands, snapchat filters and many more! There are three primary ways they're used:

    - *Clustering*: Identifying clusters within a dataset like identifying disease outbreak clusters or in natural language processing, in creating word clouds that are semantically related, etc.

    - *Dimensionality Reduction/Feature Extraction*: They can be used to condense the number of features in a dataset with a high number of features before applying a supervised learning algorithm.

    - *Automated Labelling/Tagging*: Unsupervised learning algorithms are immensely useful in categorizing uncategorized data and one can then perform the familiar classification/regression tasks using supervised learning.

In this module we will focus on two of the most commonly used unsupervised learning techniques -Principal Component Analysis (PCA) and K-Means Clustering. The former is most often used for dimensionality reduction and the latter is used in clustering problems primarily. After this module you will be able to:

    - Perform dimensionality reduction using PCA

    - Classify images using PCA

    - Find clusters within data using K-Means

    - Extract features using PCA and K-Means

      [[./k_means_clustering.gif]]
