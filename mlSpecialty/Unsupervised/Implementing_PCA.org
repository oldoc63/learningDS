
* Introduction to Implementing PCA
In this lesson, we will be implementing Principal Component Analysis (PCA) using the Python libraries NumPy and scikit-learn.

The motivation of Principal Component Analysis (PCA) is to find a new set of features that are oredered by the amount of variation (and therefore, information) they contain. We can then select a subset of these PCA features. This leaves us with lower-dimensional data that still retains most of the information contained in the larger dataset.

In this lesson, we will:

    - Implement PCA in Numpy step-by-step

    - Implement PCA in scikit-learn using only a few lines of code

    - Use principal components to train a machine learning model

    - Visualize principal components using image data

For the next few exercises, we will use a dataset that describes several types of dry beans separated into seven categories.

We will begin by taking a look at the features that describe different categories of beans.

** Task 1
A file named ~Dry_Bean.csv~ is loaded for you as a Pandas DataFrame named ~df~. Print the head of the DataFrame. Note that all the columns are numerical except for the ~Class~ column.

** Task 2
Extract the numerical features from ~df~ by dropping the ~'Class'~ column, and save them as a new DataFrame called ~data_matrix~.

** Script.py

#+begin_src python :results output
  import pandas as pd

  # Read de csv data as a DataFrame
  df = pd.read_csv('Dry_Bean.csv')

  # Remove null and na values
  df.dropna()

  # Print the DataFrame head
  print(df.head())

  # Extract the numerical columns
  data_matrix = df.drop(columns='Class')

  # Extract the classes
  classes = df['Class']

  # Print data_matrix
  print(data_matrix)

#+end_src

#+RESULTS:
#+begin_example
    Area  Perimeter  MajorAxisLength  ...  ShapeFactor3  ShapeFactor4  Class
0  28395    610.291       208.178117  ...      0.834222      0.998724  SEKER
1  28734    638.018       200.524796  ...      0.909851      0.998430  SEKER
2  29380    624.110       212.826130  ...      0.825871      0.999066  SEKER
3  30008    645.884       210.557999  ...      0.861794      0.994199  SEKER
4  30140    620.134       201.847882  ...      0.941900      0.999166  SEKER

[5 rows x 17 columns]
        Area  Perimeter  ...  ShapeFactor3  ShapeFactor4
0      28395    610.291  ...      0.834222      0.998724
1      28734    638.018  ...      0.909851      0.998430
2      29380    624.110  ...      0.825871      0.999066
3      30008    645.884  ...      0.861794      0.994199
4      30140    620.134  ...      0.941900      0.999166
...      ...        ...  ...           ...           ...
13606  42097    759.696  ...      0.642988      0.998385
13607  42101    757.499  ...      0.676099      0.998219
13608  42139    759.321  ...      0.676884      0.996767
13609  42147    763.779  ...      0.668237      0.995222
13610  42159    772.237  ...      0.616221      0.998180

[13611 rows x 16 columns]
#+end_example

* Implementing PCA in Numpy I
In this exercise, we will perform PCA using the NumPy method ~np.linalg.eig~, which performs eigendecomposition and outputs the eigenvalues and eigenvectors.

The *eigenvalues* are related to the relative variation described by each principal component. The *eigenvectors* are also known as the principal axes. They tell us how to transform (rotate) our data into new features that capture this variation.

To implement this in Python:

#+begin_src python
  correlation_matrix = data_matrix.corr()
  eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)
#+end_src

    1. First, we generate a correlation matrix using ~.corr()~

    2. Next, we use ~np.linalg.eig()~ to perform eigendecomposition on the correlation matrix. This gives us two outputs -the eigenvalues and eigenvectors.

** Task 1
The DataFrame that you created in the previous exercise, ~data_matrix~, is loaded for you. Find the correlation matrix for the features in ~data_matrix~ and save the result as ~correlation_matrix~.

Uncomment the lines that show the heatmap and notice that there are pairs of features with very high correlations.

** Task 2
Using the ~correlation_matrix~, find the eigenvalues and eigenvectors using the NumPy method ~np.linalg.eig()~. Save them as ~eigenvalues~ and ~eigenvectors~, respectively, then print them out.

You should see that ~eigenvalues~ contains 16 numbers, while ~eigenvectors~ contains 16 vectors with 16 values each.

*Hint*
Use the method ~np.linalg.eig(data_matrix)~ to retrieve the eigenvalues and eigenvectors.

** Script.py

#+begin_src python :results output
  import numpy as np
  import pandas as pd
  import matplotlib.pyplot as plt
  import seaborn as sns

  # Read de csv data as a DataFrame
  df = pd.read_csv('Dry_Bean.csv')

  # Remove null and na values
  df.dropna()

  # Extract the numerical columns
  data_matrix = df.drop(columns='Class')

  # Extract the classes
  classes = df['Class']

  # Use the .corr() method on data_matrix to get the correlation matrix
  correlation_matrix = data_matrix.corr()

  # Heatmap code:
  red_blue = sns.diverging_palette(220, 20, as_cmap=True)
  sns.heatmap(correlation_matrix, vmin = -1, vmax = 1, cmap = red_blue)
  plt.show()

  # Perform decomposition using np.linalg.eig
  eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

  print('eigenvectors: ')
  print(eigenvectors)

  print('eigenvalues: ')
  print(eigenvalues)

#+end_src

#+RESULTS:
#+begin_example
eigenvectors:
[[ 2.82457959e-01  2.45882017e-01 -6.14466787e-02 -3.15461931e-02
  -9.13256234e-02 -3.66390029e-01  1.25044861e-01  7.17479179e-02
   3.50665669e-02 -3.90419516e-01 -1.77686475e-01  5.44842282e-02
   4.62948861e-02  6.55727948e-01  2.31435926e-01  1.33190281e-01]
 [ 3.10891123e-01  1.79302922e-01 -1.88525952e-02 -4.24678975e-02
   8.18198663e-02 -1.02508210e-02  8.15296990e-02  3.17295058e-02
  -1.57501171e-01  3.44383066e-01  1.99453621e-01 -7.50549982e-01
   3.17920275e-01  8.13901113e-02  1.46143834e-02  1.26584691e-02]
 [ 3.25823976e-01  1.00756516e-01 -8.46919067e-02 -6.79308126e-03
  -4.42163116e-02 -1.49091929e-02  1.18162546e-01 -2.00947006e-01
  -3.52366452e-01  1.01996482e-01  1.73639683e-01  2.73549959e-02
  -6.85301970e-01 -1.86251185e-01  3.46019418e-01  1.74431583e-01]
 [ 2.36199383e-01  3.43460651e-01  7.50039030e-03 -6.12997105e-02
  -4.29258549e-03 -2.78820146e-02 -6.23528140e-02  9.47252766e-02
   4.14230636e-01  4.81150315e-01  4.73720993e-03  4.13935449e-01
   2.58014714e-01 -1.83095642e-01  3.31749325e-01  1.55445406e-01]
 [ 2.29298328e-01 -3.30844185e-01 -1.69058011e-01  5.36461191e-02
  -2.47566532e-02  7.59699103e-02  3.67891855e-01 -5.29805906e-01
   1.21518443e-01  2.08046178e-01 -5.40202985e-01 -3.34425476e-03
   8.74672429e-02  2.66661427e-02 -1.23575706e-01  1.02810024e-01]
 [ 2.31526055e-01 -3.19433875e-01 -1.63042022e-01  1.18388551e-01
  -6.03039593e-02 -1.90427992e-01 -5.11031662e-01  4.09120604e-01
  -3.22591880e-01  2.41533155e-01 -4.11402535e-01  3.41133220e-02
  -2.23275476e-02  4.59487115e-05  1.47926800e-02 -4.23063139e-02]
 [ 2.83199889e-01  2.44630067e-01 -5.36490752e-02 -3.09595575e-02
  -8.91133649e-02 -3.69215707e-01  1.21178732e-01  6.45192756e-02
   2.58278807e-02 -3.94275552e-01 -1.79002314e-01 -7.73945617e-02
   1.02365543e-01 -6.48621711e-01 -2.24752670e-01 -1.30973875e-01]
 [ 2.97483844e-01  2.22802185e-01 -4.99135477e-02 -3.24273855e-02
  -2.19534105e-02 -3.35147364e-02 -6.30912872e-04 -3.40422281e-02
  -1.66940989e-02  2.53700143e-01  1.96001889e-01  2.74139585e-01
  -1.98496927e-01  2.66409059e-01 -6.75588993e-01 -3.32487860e-01]
 [-5.98079606e-02  2.20619259e-01 -8.52582080e-02  9.48254269e-01
   1.97598918e-01  5.10553897e-04  4.45929047e-02 -1.47000878e-02
   6.00988144e-03 -8.95631344e-04 -2.77069112e-03 -4.38701370e-05
   4.62379038e-04 -5.65700266e-05 -4.74695176e-06 -1.17646776e-06]
 [-1.43016314e-01  1.03322337e-01 -7.38670228e-01 -4.95457556e-02
  -2.82194373e-01  3.25692613e-01  3.09528792e-01  3.72834092e-01
  -1.24670321e-02 -6.14713024e-03  8.92367231e-04  3.39336586e-04
   5.39707165e-04 -7.67128823e-03 -2.11537089e-03 -1.38727448e-03]
 [-2.48164811e-01  2.14805282e-01 -1.63325487e-01  6.74824148e-02
  -6.48700706e-01 -1.73439085e-01 -4.16624414e-01 -4.61145752e-01
   9.44150591e-03  7.30163366e-02  3.45701555e-02 -1.20891182e-01
   4.96397316e-02  1.46685284e-02  1.89361431e-03  2.37532217e-03]
 [-2.38378001e-01  3.28914360e-01  1.49700768e-01 -8.71555716e-02
   5.85957324e-02  1.23232305e-02 -3.24244642e-02  1.67809467e-01
   3.93833779e-02  1.17265401e-01 -3.22502975e-01 -1.53253508e-01
  -2.54641355e-01  2.02577299e-03 -3.72516051e-01  6.52515601e-01]
 [-2.21318903e-01 -3.32548514e-01 -3.26229309e-02  7.23303405e-02
  -1.12907779e-01 -6.33211910e-01  2.93567734e-01  1.91922106e-01
   3.36948538e-01  2.71583838e-01  2.00505414e-01 -1.28472846e-01
  -2.30735279e-01  4.01059407e-03 -1.12850106e-02 -5.46798048e-03]
 [-3.14624593e-01  1.29419241e-01  1.20076675e-01 -4.65438196e-02
  -2.64141427e-02 -2.59245737e-01  3.54310851e-01 -3.19852488e-02
  -6.59508821e-01  2.12589947e-01 -3.73372481e-02  2.97904717e-01
   3.19900059e-01 -1.85035834e-02  1.46683912e-02  5.54470208e-03]
 [-2.38983301e-01  3.27521662e-01  1.49570241e-01 -9.56788529e-02
   6.22269463e-02  4.74498436e-02  8.31848115e-02  4.52594153e-02
   9.00540674e-02  1.65952214e-01 -4.68319821e-01 -1.89335830e-01
  -2.82232572e-01  4.61837470e-02  2.34064701e-01 -6.01334519e-01]
 [-1.98009429e-01  1.00061082e-01 -5.36903055e-01 -2.10119897e-01
   6.40371689e-01 -2.80088867e-01 -2.40046279e-01 -2.66748910e-01
   2.97986049e-03 -3.46314997e-03  2.84785031e-02  9.79933869e-03
   2.73100957e-03 -4.29724599e-03  1.03771345e-02  6.16002748e-04]]
eigenvalues:
[8.87463018e+00 4.22895571e+00 1.28105028e+00 8.18252847e-01
 4.38286865e-01 1.83961749e-01 1.11624116e-01 5.20132000e-02
 8.26026072e-03 1.45388993e-03 1.05418870e-03 2.93982938e-04
 1.48794566e-04 1.00102669e-05 1.78479175e-06 2.14611337e-06]
#+end_example
